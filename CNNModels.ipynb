{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLKNOK0_h5Ym"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "\n",
    "# TODO:\n",
    "# Check valid input sizes for each model and put into docstring.\n",
    "# CAN INCLUDE PREDIFINED MODELS FROM keras.applications.{MODEL_NAME}\n",
    "# INCLUDING MobileNet, MobileNetV2, MobileNetV3, VGG16, VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leNet5(num_classes):\n",
    "    model = Sequential()\n",
    "    # Layer C1\n",
    "    model.add(Conv2D(filters=6,\n",
    "                     kernel_size=(5,5),\n",
    "                     activation='relu',\n",
    "                     input_shape=(28,28,1)))\n",
    "    # Layer S2\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Layer C3\n",
    "    model.add(Conv2D(filters=16,\n",
    "                     kernel_size=(5,5),\n",
    "                     activation='relu'))\n",
    "    # Layer S4\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Flatten units\n",
    "    model.add(Flatten())\n",
    "    # Layer C5\n",
    "    model.add(Dense(units=120,\n",
    "                    activation='relu'))\n",
    "    # Layer F6\n",
    "    model.add(Dense(units=84,\n",
    "                    activation='relu'))\n",
    "    # Output layer\n",
    "    model.add(Dense(units=num_classes,\n",
    "                    activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexNet(num_classes):\n",
    "    \"\"\"\n",
    "    The model takes an RGB image of fixed size (224x224 pixels) as input.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    # 1st Convolutional Layer\n",
    "    model.add(Conv2D(filters=96,\n",
    "                     input_shape=(224,224,3),\n",
    "                     kernel_size=(11,11),\n",
    "                     strides=(4,4),\n",
    "                     activation='relu'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    # 2nd Convolutional Layer\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(11,11),\n",
    "                     activation='relu'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    # 3rd Convolutional Layer\n",
    "    model.add(Conv2D(filters=384,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu'))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    # 4th Convolutional Layer\n",
    "    model.add(Conv2D(filters=384,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu'))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    # 5th Convolutional Layer\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    # Flattening\n",
    "    model.add(Flatten())\n",
    "    # 1st Dense Layer\n",
    "    model.add(Dense(units=4096,\n",
    "                    input_shape=(224*224*3, ),\n",
    "                    activation='relu'))\n",
    "    # Add Dropout to prevent overfitting\n",
    "    model.add(Dropout(0.4))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    # 2nd Dense Layer\n",
    "    model.add(Dense(units=4096,\n",
    "              activation='relu'))\n",
    "    # Add Dropout\n",
    "    model.add(Dropout(0.4))\n",
    "    # Batch Normalisation\n",
    "    model.add(BatchNormalization())\n",
    "    # Output Softmax Layer\n",
    "    model.add(Dense(units=num_classes,\n",
    "                    activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16C(num_classes):\n",
    "    \"\"\"\n",
    "    VGG-16 configuration C\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    # Block 1\n",
    "    # Convolution Layer 1.1\n",
    "    model.add(Conv2D(filters=64,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     input_shape=(224,224,3),\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 1.2\n",
    "    model.add(Conv2D(filters=64,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Block 2\n",
    "    # Convolution Layer 2.1\n",
    "    model.add(Conv2D(filters=128,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 2.2\n",
    "    model.add(Conv2D(filters=128,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Block 3\n",
    "    # Convolution Layer 3.1\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 3.2\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 3.3\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(1,1),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Block 4\n",
    "    # Convolution Layer 4.1\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 4.2\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 4.3\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(1,1),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Block 5\n",
    "    # Convolution Layer 5.1\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 5.2\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 5.3\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(1,1),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Flattening\n",
    "    model.add(Flatten())\n",
    "    # Fully Connected Layers\n",
    "    # Fully Connected 1\n",
    "    model.add(Dense(units=4096,\n",
    "                    activation='relu'))\n",
    "    # Fully Connected 2\n",
    "    model.add(Dense(units=4096,\n",
    "                    activation='relu'))\n",
    "    # Fully Connected 3 (OUTPUT)\n",
    "    model.add(Dense(units=num_classes,\n",
    "                    activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16(num_classes):\n",
    "    \"\"\"\n",
    "    VGG-16 configuration D\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    # Block 1\n",
    "    # Convolution Layer 1.1\n",
    "    model.add(Conv2D(filters=64,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     input_shape=(224,224,3),\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 1.2\n",
    "    model.add(Conv2D(filters=64,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Block 2\n",
    "    # Convolution Layer 2.1\n",
    "    model.add(Conv2D(filters=128,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 2.2\n",
    "    model.add(Conv2D(filters=128,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Block 3\n",
    "    # Convolution Layer 3.1\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 3.2\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 3.3\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Block 4\n",
    "    # Convolution Layer 4.1\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 4.2\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 4.3\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Block 5\n",
    "    # Convolution Layer 5.1\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 5.2\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 5.3\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Flattening\n",
    "    model.add(Flatten())\n",
    "    # Fully Connected Layers\n",
    "    # Fully Connected 1\n",
    "    model.add(Dense(units=4096,\n",
    "                    activation='relu'))\n",
    "    # Fully Connected 2\n",
    "    model.add(Dense(units=4096,\n",
    "                    activation='relu'))\n",
    "    # Fully Connected 3 (OUTPUT)\n",
    "    model.add(Dense(units=num_classes,\n",
    "                    activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg19(num_classes):\n",
    "    model = Sequential()\n",
    "    # Block 1\n",
    "    # Convolution Layer 1.1\n",
    "    model.add(Conv2D(filters=64,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     input_shape=(224,224,3),\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 1.2\n",
    "    model.add(Conv2D(filters=64,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Block 2\n",
    "    # Convolution Layer 2.1\n",
    "    model.add(Conv2D(filters=128,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 2.2\n",
    "    model.add(Conv2D(filters=128,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Block 3\n",
    "    # Convolution Layer 3.1\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 3.2\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 3.3\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 3.4\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Block 4\n",
    "    # Convolution Layer 4.1\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 4.2\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 4.3\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 4.4\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Block 5\n",
    "    # Convolution Layer 5.1\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 5.2\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 5.3\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Convolution Layer 5.4\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    # Max-Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Flattening\n",
    "    model.add(Flatten())\n",
    "    # Fully Connected Layers\n",
    "    # Fully Connected 1\n",
    "    model.add(Dense(units=4096,\n",
    "                    activation='relu'))\n",
    "    # Fully Connected 2\n",
    "    model.add(Dense(units=4096,\n",
    "                    activation='relu'))\n",
    "    # Fully Connected 3 (OUTPUT)\n",
    "    model.add(Dense(units=num_classes,\n",
    "                    activation='softmax'))\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
